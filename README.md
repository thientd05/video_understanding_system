# Video RAG Chat Interface

Chat with videos using Retrieval Augmented Generation (RAG) and an LLM.

### Demo link: https://youtu.be/ZiRbgEmONZU

## ğŸš€ How to Run

### Web Interface (Gradio) â€” **Recommended on Ubuntu**

```bash
cd ~your_dir # when cloned my repo
./run_web_app.sh
```

Then open your browser and visit: **http://localhost:7860**


## ğŸ“± Web Interface Features

### Video Loading
- ğŸ“ Upload your video file
- ğŸ”„ Load & Initialize - load the video and initialize the embedding model
- âœ… Status indicator - display the load status

### Chat Interface
- ğŸ’¬ Chat History - display the entire conversation
- â“ Question Input - enter and send questions about the video
- ğŸ¤– Real-time Streaming - watch each generated token in real time

### Features
- âš¡ **Real-time Streaming**: Watch the LLM emit tokens as it responds
- ğŸ¬ **Multi-modal**: Combine ASR (audio), OCR (text), and visuals (frames)
- ğŸ” **RAG-based**: Retrieve relevant context before generating the answer
- ğŸ¨ **Beautiful UI**: Modern interface built with Gradio

## ğŸ—ï¸ Architecture

### Components

```
src/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ embedding.py      # Embedding processing
â”‚   â””â”€â”€ video_rag.py      # VideoRAG
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ styles.css        # Css for UI
â”‚   â””â”€â”€ web_app.py        # Gradio Web Interface
â””â”€â”€ utils/
    â”œâ”€â”€ asr.py            # Speech-to-text
    â”œâ”€â”€ ocr.py            # Optical Character Recognition
    â”œâ”€â”€ video_processing.py
    â””â”€â”€ choose_frame.py
```
### Sample Video
```
â”œâ”€â”€ src/
â””â”€â”€ Is_the_future_of_AI_physical_Ian_Bremmer_Explains.mp4      # Sample video
```

### Workflow

1. **Video Loading** â†’ `EmbeddingManager`
   - Process video frames
   - Run ASR (transcribe audio)
   - Run OCR (extract text from frames)
   - Embed all text with `SentenceTransformer`
   - Store everything inside FAISS databases

2. **Question Answering** â†’ `VideoRAG`
   - Retrieve context â€” determine what information to fetch
   - Search â€” find relevant transcriptions/OCR texts
   - Answer â€” generate the reply with the LLM
   - Streaming â€” print each token in real time

## âš™ï¸ Requirements

- Python 3.10+
- CUDA-capable GPU (optional but recommended)
- Video files: MP4, AVI, MOV, MKV

### Installed Packages

- `llama-cpp-python` - LLM inference
- `sentence-transformers` - Embedding model
- `faiss-cpu` - Vector search
- `gradio` - Web UI
- `PyQt6` - Desktop UI (optional)
- `opencv-python` - Video processing
- `openai-whisper` - Speech recognition
- `easyocr` - Text recognition
Check the requirements.txt!

## ğŸ“ Usage Examples

### Web Interface

1. **Load Video**
   ```
   Video Path: /path/to/your/video.mp4
   Click: Load & Initialize
   Wait for: âœ… Video loaded successfully!
   ```

2. **Ask Questions**
   ```
   Question: What did the speaker say about AI?
   Click: Send Question
   Watch: Answer streams in real-time
   ```

## ğŸ¯ Tips

- **First load**: Takes roughly 10â€“20 seconds depending on video length
- **GPU Memory**: If you hit GPU memory limits, reduce `n_gpu_layers` in `VideoRAG`
- **Large Videos**: Split very large videos into smaller chunks
- **Accuracy**: Prompt engineering has a big impact on answer quality

## ğŸ› Troubleshooting

### GPU Out of Memory
- Reduce `n_gpu_layers` from 32 to around under 30
- Lower the context length `n_ctx` from 4096 to 2048

### Video failed to load
- Verify the video format: MP4, AVI, MOV, MKV
- Try converting the file: `ffmpeg -i input.video -c:v libx264 output.mp4`

## ğŸ“Š Performance

| Task | Time | GPU Memory |
|------|------|-----------|
| Load Video (47 frames) | 10-12 sec | ~4GB |
| Answer | 12-14 sec | ~4GB |

## ğŸ“š References

- [Gradio Docs](https://www.gradio.app/)
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
